{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 13. Loading and Preprocessing Data with TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "project goal: Data API, TFRecord TF Transform, TF Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import os\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)> \n",
      "\n",
      "Inside dataset:\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n",
      "tf.Tensor(5, shape=(), dtype=int32)\n",
      "tf.Tensor(6, shape=(), dtype=int32)\n",
      "tf.Tensor(7, shape=(), dtype=int32)\n",
      "tf.Tensor(8, shape=(), dtype=int32)\n",
      "tf.Tensor(9, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# from_tensor_slices() 會將接收的X建立 tf.data.Dataset, 所有元素都是X的切片 \n",
    "X = tf.range(10)\n",
    "dataset = tf.data.Dataset.from_tensor_slices(X)\n",
    "print(dataset, \"\\n\")\n",
    "print(\"Inside dataset:\")\n",
    "for item in dataset:\n",
    "    print(item)           # 所以 dataset 裡面是 tensor 0, 1, 2, ..., 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After shuffle:\n",
      "tf.Tensor([1 3 0 4 2 5 6], shape=(7,), dtype=int64)\n",
      "tf.Tensor([8 7 1 0 3 2 5], shape=(7,), dtype=int64)\n",
      "tf.Tensor([4 6 9 8 9 7 0], shape=(7,), dtype=int64)\n",
      "tf.Tensor([3 1 4 5 2 8 7], shape=(7,), dtype=int64)\n",
      "tf.Tensor([6 9], shape=(2,), dtype=int64)\n"
     ]
    }
   ],
   "source": [
    "# 可以對於 dataset 做一些操作\n",
    "# 注意: dataset的method不會修改原來資料組, 而是建立新的資料組去操作！\n",
    "\n",
    "# .repeat(3).batch(7) 代表 在新的資料集中將資料重複串接三次, 再將每7個分成一組\n",
    "dataset = dataset.repeat(3).batch(7)\n",
    "# 輸出會是：\n",
    "# tf.Tensor([0 1 2 3 4 5 6], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([7 8 9 0 1 2 3], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([4 5 6 7 8 9 0], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([1 2 3 4 5 6 7], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([8 9], shape=(2,), dtype=int32)\n",
    "\n",
    "# map() 可以用來轉換項目\n",
    "dataset = dataset.map(lambda x: x * 2)\n",
    "# 輸出會是每一項都乘上2:\n",
    "# tf.Tensor([ 0  4  8 12 16 20 24], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([28 32 36  0  4  8 12], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([16 20 24 28 32 36  0], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([ 4  8 12 16 20 24 28], shape=(7,), dtype=int32)\n",
    "# tf.Tensor([32 36], shape=(2,), dtype=int32)\n",
    "\n",
    "# unbatch() 將dataset拆開成單獨一項\n",
    "dataset = dataset.unbatch()\n",
    "\n",
    "# 或是用 filter() 來過濾資料組\n",
    "dataset = dataset = dataset.filter(lambda x: x < 10)\n",
    "\n",
    "# 以及 shuffle() 將實例洗亂\n",
    "tf.random.set_seed(42)\n",
    "dataset = tf.data.Dataset.range(10).repeat(3)\n",
    "dataset = dataset.shuffle(buffer_size=3, seed=42).batch(7)\n",
    "print(\"After shuffle:\")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 範例1. Split the California dataset to multiple CSV files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target.reshape(-1, 1), random_state=42\n",
    ")\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_mean = scaler.mean_\n",
    "X_std = scaler.scale_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通常在處理沒辦法存進memory的大型資料時, 我們會先將其分成很多個file, 再讓tensorflow去平行讀取他們"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_multiple_csv_files(data, name_prefix, header=None, n_parts=10):\n",
    "    housing_dir = os.path.join(\"datasets\", \"housing\")\n",
    "    os.makedirs(housing_dir, exist_ok=True)\n",
    "    path_format = os.path.join(housing_dir, \"my_{}_{:02d}.csv\")\n",
    "\n",
    "    filepaths = []\n",
    "    m = len(data)\n",
    "    for file_idx, row_indices in enumerate(np.array_split(np.arange(m), n_parts)):\n",
    "        part_csv = path_format.format(name_prefix, file_idx)\n",
    "        filepaths.append(part_csv)\n",
    "        with open(part_csv, \"wt\", encoding=\"utf-8\") as f:\n",
    "            if header is not None:\n",
    "                f.write(header)\n",
    "                f.write(\"\\n\")\n",
    "            for row_idx in row_indices:\n",
    "                f.write(\",\".join([repr(col) for col in data[row_idx]]))\n",
    "                f.write(\"\\n\")\n",
    "    return filepaths\n",
    "\n",
    "train_data = np.c_[X_train, y_train]\n",
    "valid_data = np.c_[X_valid, y_valid]\n",
    "test_data = np.c_[X_test, y_test]\n",
    "header_cols = housing.feature_names + [\"MedianHouseValue\"]\n",
    "header = \",\".join(header_cols)\n",
    "\n",
    "train_filepaths = save_to_multiple_csv_files(train_data, \"train\", header, n_parts=20)\n",
    "valid_filepaths = save_to_multiple_csv_files(valid_data, \"valid\", header, n_parts=10)\n",
    "test_filepaths = save_to_multiple_csv_files(test_data, \"test\", header, n_parts=10)\n",
    "\n",
    "# 經過上面的轉換後, training dataset 被分配到20個csv file中,\n",
    "# validation & testing dataset 也各自被分配到10個csv file中\n",
    "# 而他們都存在資料夾 datasets 裡面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedianHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.5214</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.049945</td>\n",
       "      <td>1.106548</td>\n",
       "      <td>1447.0</td>\n",
       "      <td>1.605993</td>\n",
       "      <td>37.63</td>\n",
       "      <td>-122.43</td>\n",
       "      <td>1.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.3275</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.490060</td>\n",
       "      <td>0.991054</td>\n",
       "      <td>3464.0</td>\n",
       "      <td>3.443340</td>\n",
       "      <td>33.69</td>\n",
       "      <td>-117.39</td>\n",
       "      <td>1.687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.1000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7.542373</td>\n",
       "      <td>1.591525</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>2.250847</td>\n",
       "      <td>38.44</td>\n",
       "      <td>-122.98</td>\n",
       "      <td>1.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.1736</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.289003</td>\n",
       "      <td>0.997442</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>2.695652</td>\n",
       "      <td>33.55</td>\n",
       "      <td>-117.70</td>\n",
       "      <td>2.621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0549</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.312457</td>\n",
       "      <td>1.085092</td>\n",
       "      <td>3297.0</td>\n",
       "      <td>2.244384</td>\n",
       "      <td>33.93</td>\n",
       "      <td>-116.93</td>\n",
       "      <td>0.956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  3.5214      15.0  3.049945   1.106548      1447.0  1.605993     37.63   \n",
       "1  5.3275       5.0  6.490060   0.991054      3464.0  3.443340     33.69   \n",
       "2  3.1000      29.0  7.542373   1.591525      1328.0  2.250847     38.44   \n",
       "3  7.1736      12.0  6.289003   0.997442      1054.0  2.695652     33.55   \n",
       "4  2.0549      13.0  5.312457   1.085092      3297.0  2.244384     33.93   \n",
       "\n",
       "   Longitude  MedianHouseValue  \n",
       "0    -122.43             1.442  \n",
       "1    -117.39             1.687  \n",
       "2    -122.98             1.621  \n",
       "3    -117.70             2.621  \n",
       "4    -116.93             0.956  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.read_csv(train_filepaths[0]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 建立 input 的 pipeline\n",
    "# interleave() 可以一次讀取 cycle_length 個檔案, 並讓他們的資料交錯排列\n",
    "# skip(1)代表跳過檔案的第一row (標頭列)\n",
    "\n",
    "filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)\n",
    "n_readers = 5\n",
    "dataset = filepath_dataset.interleave(\n",
    "    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "    cycle_length=n_readers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 首先, preprocessing\n",
    "# 前面已經計算過 X_mean 及 X_std, 他們都是1D tensor, 裡面有8個浮點數(每個輸入特徵一個)\n",
    "\n",
    "n_inputs = 8\n",
    "\n",
    "@tf.function\n",
    "def preprocess(line):\n",
    "    defs = [0.] * n_inputs + [tf.constant([], dtype=tf.float32)]\n",
    "    # decode_csv(要解析的列, 含有各欄default值的array)\n",
    "    # 所以 defs 告訴他, 各特徵欄都是浮點數0, 而最後一欄(target的預設值)是沒有預設值的浮點數\n",
    "    fields = tf.io.decode_csv(line, record_defaults=defs)\n",
    "    # 因為decode_csv的回傳值會是每欄一個的list, 所以用tf.stack把他疊成1D tensor\n",
    "    x = tf.stack(fields[:-1])\n",
    "    y = tf.stack(fields[-1:])\n",
    "    return (x - X_mean) / X_std, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_reader_dataset(filepaths, repeat=1, n_readers=5,\n",
    "                       n_read_threads=None, shuffle_buffer_size=10000, \n",
    "                       n_parse_threads=5, batch_size=32):\n",
    "    dataset = tf.data.Dataset.list_files(filepaths).repeat(repeat)\n",
    "    dataset = dataset.interleave(\n",
    "        lambda filepath: tf.data.TextLineDataset(filepath).skip(1),\n",
    "        cycle_length=n_readers, num_parallel_calls=n_read_threads\n",
    "    )\n",
    "    dataset = dataset.shuffle(shuffle_buffer_size)\n",
    "    dataset = dataset.map(preprocess, num_parallel_calls=n_parse_threads)\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    return dataset.prefetch(1)\n",
    "\n",
    "# 上述method的流程：\n",
    "# 載入所有csv並重複n次(這裡是1), interleave()一次讀取多個檔案並交錯排列, shuffle()洗亂\n",
    "# map()做preprocess, 最後batch將他們分批"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prefetch: 讓GPU在處理某一個batch時, 就平行讓CPU先從dataset準備好下一個batch, 可以大幅提升性能！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.SGD` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.SGD`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "362/362 [==============================] - 1s 924us/step - loss: 2.3284 - val_loss: 9.1637\n",
      "Epoch 2/10\n",
      "362/362 [==============================] - 0s 1ms/step - loss: 1.0345 - val_loss: 0.9127\n",
      "Epoch 3/10\n",
      "362/362 [==============================] - 0s 782us/step - loss: 0.7136 - val_loss: 0.7135\n",
      "Epoch 4/10\n",
      "362/362 [==============================] - 0s 852us/step - loss: 0.6939 - val_loss: 0.6446\n",
      "Epoch 5/10\n",
      "362/362 [==============================] - 0s 731us/step - loss: 0.6604 - val_loss: 0.6862\n",
      "Epoch 6/10\n",
      "362/362 [==============================] - 0s 688us/step - loss: 0.6222 - val_loss: 0.6997\n",
      "Epoch 7/10\n",
      "362/362 [==============================] - 0s 684us/step - loss: 0.5914 - val_loss: 0.5534\n",
      "Epoch 8/10\n",
      "362/362 [==============================] - 0s 674us/step - loss: 0.5865 - val_loss: 0.5276\n",
      "Epoch 9/10\n",
      "362/362 [==============================] - 0s 656us/step - loss: 0.5439 - val_loss: 0.5085\n",
      "Epoch 10/10\n",
      "362/362 [==============================] - 0s 686us/step - loss: 0.5111 - val_loss: 0.4906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x130057a30>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 開始建立 dataset & 執行 preprocess\n",
    "train_set = csv_reader_dataset(train_filepaths, repeat=None)\n",
    "valid_set = csv_reader_dataset(valid_filepaths)\n",
    "test_set = csv_reader_dataset(test_filepaths)\n",
    "\n",
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1),\n",
    "])\n",
    "model.compile(loss=\"mse\", optimizer=keras.optimizers.SGD(learning_rate=1e-3))\n",
    "batch_size = 32\n",
    "model.fit(train_set, steps_per_epoch=len(X_train) // batch_size, epochs=10,\n",
    "          validation_data=valid_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 575us/step - loss: 0.5066\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5065754652023315"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluation\n",
    "model.evaluate(test_set, steps=len(X_test) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161/161 [==============================] - 0s 672us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.515468 ],\n",
       "       [1.1707823],\n",
       "       [3.0246022],\n",
       "       ...,\n",
       "       [2.0176928],\n",
       "       [1.6959119],\n",
       "       [2.1857405]], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict\n",
    "new_set = test_set.map(lambda X, y: X)     # 把 y(label) 拿掉來預測\n",
    "X_new = X_test\n",
    "model.predict(new_set, steps=len(X_new) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 也可以自己寫train, 再轉成 tf.function 加速！\n",
    "\n",
    "optimizer = keras.optimizers.Nadam(learning_rate=0.01)\n",
    "loss_fn = keras.losses.mean_squared_error\n",
    "\n",
    "@tf.function\n",
    "def train(model, n_epochs, batch_size=32,\n",
    "          n_readers=5, n_read_threads=5, shuffle_buffer_size=10000, n_parse_threads=5):\n",
    "    train_set = csv_reader_dataset(train_filepaths, repeat=n_epochs, n_readers=n_readers,\n",
    "                       n_read_threads=n_read_threads, shuffle_buffer_size=shuffle_buffer_size,\n",
    "                       n_parse_threads=n_parse_threads, batch_size=batch_size)\n",
    "    for X_batch, y_batch in train_set:\n",
    "        with tf.GradientTape() as tape:\n",
    "            y_pred = model(X_batch)\n",
    "            main_loss = tf.reduce_mean(loss_fn(y_batch, y_pred))\n",
    "            loss = tf.add_n([main_loss] + model.losses)\n",
    "        gradients = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "train(model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "● apply()              Applies a transformation function to this dataset.\n",
      "● as_numpy_iterator()  Returns an iterator which converts all elements of the dataset to numpy.\n",
      "● batch()              Combines consecutive elements of this dataset into batches.\n",
      "● bucket_by_sequence_length()A transformation that buckets elements in a `Dataset` by length.\n",
      "● cache()              Caches the elements in this dataset.\n",
      "● cardinality()        Returns the cardinality of the dataset, if known.\n",
      "● choose_from_datasets()Creates a dataset that deterministically chooses elements from `datasets`.\n",
      "● concatenate()        Creates a `Dataset` by concatenating the given dataset with this dataset.\n",
      "● counter()            Creates a `Dataset` that counts from `start` in steps of size `step`.\n",
      "● element_spec()       The type specification of an element of this dataset.\n",
      "● enumerate()          Enumerates the elements of this dataset.\n",
      "● filter()             Filters this dataset according to `predicate`.\n",
      "● flat_map()           Maps `map_func` across this dataset and flattens the result.\n",
      "● from_generator()     Creates a `Dataset` whose elements are generated by `generator`. (deprecated arguments)\n",
      "● from_tensor_slices() Creates a `Dataset` whose elements are slices of the given tensors.\n",
      "● from_tensors()       Creates a `Dataset` with a single element, comprising the given tensors.\n",
      "● get_single_element() Returns the single element of the `dataset`.\n",
      "● group_by_window()    Groups windows of elements by key and reduces them.\n",
      "● ignore_errors()      Drops elements that cause errors.\n",
      "● interleave()         Maps `map_func` across this dataset, and interleaves the results.\n",
      "● list_files()         A dataset of all files matching one or more glob patterns.\n",
      "● load()               Loads a previously saved dataset.\n",
      "● map()                Maps `map_func` across the elements of this dataset.\n",
      "● options()            Returns the options for this dataset and its inputs.\n",
      "● padded_batch()       Combines consecutive elements of this dataset into padded batches.\n",
      "● prefetch()           Creates a `Dataset` that prefetches elements from this dataset.\n",
      "● ragged_batch()       Combines consecutive elements of this dataset into `tf.RaggedTensor`s.\n",
      "● random()             Creates a `Dataset` of pseudorandom values.\n",
      "● range()              Creates a `Dataset` of a step-separated range of values.\n",
      "● rebatch()            Creates a `Dataset` that rebatches the elements from this dataset.\n",
      "● reduce()             Reduces the input dataset to a single element.\n",
      "● rejection_resample() Resamples elements to reach a target distribution.\n",
      "● repeat()             Repeats this dataset so each original value is seen `count` times.\n",
      "● sample_from_datasets()Samples elements at random from the datasets in `datasets`.\n",
      "● save()               Saves the content of the given dataset.\n",
      "● scan()               A transformation that scans a function across an input dataset.\n",
      "● shard()              Creates a `Dataset` that includes only 1/`num_shards` of this dataset.\n",
      "● shuffle()            Randomly shuffles the elements of this dataset.\n",
      "● skip()               Creates a `Dataset` that skips `count` elements from this dataset.\n",
      "● snapshot()           API to persist the output of the input dataset.\n",
      "● sparse_batch()       Combines consecutive elements into `tf.sparse.SparseTensor`s.\n",
      "● take()               Creates a `Dataset` with at most `count` elements from this dataset.\n",
      "● take_while()         A transformation that stops dataset iteration based on a `predicate`.\n",
      "● unbatch()            Splits elements of a dataset into multiple elements.\n",
      "● unique()             A transformation that discards duplicate elements of a `Dataset`.\n",
      "● window()             Returns a dataset of \"windows\".\n",
      "● with_options()       Returns a new `tf.data.Dataset` with the given options set.\n",
      "● zip()                Creates a `Dataset` by zipping together the given datasets.\n"
     ]
    }
   ],
   "source": [
    "# 其他可以用於 dataset 的函式\n",
    "for m in dir(tf.data.Dataset):\n",
    "    if not (m.startswith(\"_\") or m.endswith(\"_\")):\n",
    "        func = getattr(tf.data.Dataset, m)\n",
    "        if hasattr(func, \"__doc__\"):\n",
    "            print(\"● {:21s}{}\".format(m + \"()\", func.__doc__.split(\"\\n\")[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFRecord binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TFRecord 是高速儲存與讀取大量資料時的最佳TensorFlow格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create & write\n",
    "with tf.io.TFRecordWriter(\"my_data.tfrecord\") as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")\n",
    "\n",
    "# read parallelly & print\n",
    "filepaths = [\"my_data_{}.tfrecord\".format(i) for i in range(5)]\n",
    "dataset = tf.data.TFRecordDataset(filepaths, num_parallel_reads=3)\n",
    "for item in dataset:\n",
    "    print(item)\n",
    "\n",
    "# compress files\n",
    "options = tf.io.TFRecordOptions(compression_type=\"GZIP\")\n",
    "with tf.io.TFRecordWriter(\"my_compressed.tfrecord\", options) as f:\n",
    "    f.write(b\"This is the first record\")\n",
    "    f.write(b\"And this is the second record\")\n",
    "\n",
    "# read the compressed files & print\n",
    "dataset = tf.data.TFRecordDataset([\"my_compressed.tfrecord\"], \n",
    "                                  compression_type=\"GZIP\")\n",
    "for item in dataset:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "protocol buffer (protobuf, 協定緩衝區): 一種高效的二進制格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 以下這段要用protobuf compiler才能跑, 只是示範而已！\n",
    "\n",
    "# 先定義 protobuf:\n",
    "%%writefile person.proto\n",
    "syntax = \"proto3\";\n",
    "message Person {\n",
    "  string name = 1;\n",
    "  int32 id = 2;\n",
    "  repeated string email = 3;\n",
    "}\n",
    "\n",
    "# compile\n",
    "!protoc person.proto --python_out=. --descriptor_set_out=person.desc --include_imports\n",
    "\n",
    "# import & 使用\n",
    "from person_pb2.py import Person\n",
    "\n",
    "person = Person(name=\"Al\", id=123, email=[\"a@b.com\"])\n",
    "print(person)\n",
    "# output會是:\n",
    "# name: \"Al\"\n",
    "# id: 123\n",
    "# email: \"a@b.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 而 TensorFlow Protobuf 使用取來會是這樣:\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Feature, Features, Example\n",
    "\n",
    "BytesList = tf.train.BytesList\n",
    "FloatList = tf.train.FloatList\n",
    "Int64List = tf.train.Int64List\n",
    "Feature = tf.train.Feature\n",
    "Features = tf.train.Features\n",
    "Example = tf.train.Example\n",
    "\n",
    "person_example = Example(\n",
    "    features=Features(\n",
    "        feature={\n",
    "            \"name\": Feature(bytes_list=BytesList(value=[b\"Alice\"])),\n",
    "            \"id\": Feature(int64_list=Int64List(value=[123])),\n",
    "            \"emails\": Feature(bytes_list=BytesList(value=[b\"a@b.com\", b\"c@d.com\"]))\n",
    "        }))\n",
    "\n",
    "with tf.io.TFRecordWriter(\"my_contacts.tfrecord\") as f:\n",
    "    f.write(person_example.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github上面還有更多關於protobuf的操作, 可以參考一下"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "回到 California housing dataset, 開始正式做 proprocessing："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_housing_data(housing_path=\"./datasets/housing/\"):\n",
    "    csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "    return pd.read_csv(csv_path)\n",
    "    \n",
    "housing = load_housing_data()\n",
    "housing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BucketizedColumn(source_column=NumericColumn(key='median_income', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))\n",
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:21: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:21: categorical_column_with_vocabulary_list (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:23: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:23: indicator_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:24: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:24: embedding_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Keras preprocessing layers instead, either directly or via the `tf.keras.utils.FeatureSpace` utility. Each of `tf.feature_column.*` has a functional equivalent in `tf.keras.layers` for feature preprocessing when training a Keras model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:32: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /var/folders/kl/8jz9qp1s7j18_zz5yhcfm4yw0000gn/T/ipykernel_56330/1888575075.py:32: crossed_column (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.experimental.preprocessing.HashedCrossing` instead for feature crossing when preprocessing data to train a Keras model.\n"
     ]
    }
   ],
   "source": [
    "housing_median_age = tf.feature_column.numeric_column(\"housing_median_age\")\n",
    "\n",
    "# normalize \"housing_median_age\" column\n",
    "age_mean, age_std = X_mean[1], X_std[1]\n",
    "housing_median_age = tf.feature_column.numeric_column(\n",
    "    \"housing_median_age\", normalizer_fn=lambda x: (x - age_mean) / age_std)\n",
    "\n",
    "# bucketize \"median income\" column\n",
    "# bucketize可以想成把各個元素放到boundary桶子中, default會是每個桶子中都是小於等於該數字的元素\n",
    "median_income = tf.feature_column.numeric_column(\"median_income\")\n",
    "bucketized_income = tf.feature_column.bucketized_column(\n",
    "    median_income, boundaries=[1.5, 3., 4.5, 6.]\n",
    ")\n",
    "print(bucketized_income)\n",
    "# BucketizedColumn(source_column=NumericColumn(key='median_income', \n",
    "#                  shape=(1,), default_value=None, dtype=tf.float32, \n",
    "#                  normalizer_fn=None), boundaries=(1.5, 3.0, 4.5, 6.0))\n",
    "\n",
    "# 把 ocean_proximity 利用 hash映射 轉成 one-hot encoding\n",
    "ocean_prox_vocab = ['<1H OCEAN', 'INLAND', 'ISLAND', 'NEAR BAY', 'NEAR OCEAN']\n",
    "ocean_proximity = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "    \"ocean_proximity\", ocean_prox_vocab)\n",
    "ocean_proximity_one_hot = tf.feature_column.indicator_column(ocean_proximity)\n",
    "ocean_proximity_embed = tf.feature_column.embedding_column(ocean_proximity,\n",
    "                                                           dimension=2)\n",
    "\n",
    "# bucketize \"housing_median_age\" column\n",
    "bucketized_age = tf.feature_column.bucketized_column(\n",
    "    housing_median_age, boundaries=[-1., -0.5, 0., 0.5, 1.])    # age was scaled\n",
    "\n",
    "# 交叉後的特徵拿去做 hash\n",
    "age_and_ocean_proximity = tf.feature_column.crossed_column(\n",
    "    [bucketized_age, ocean_proximity], hash_bucket_size=100)\n",
    "\n",
    "# bucketize \"latitude\" column\n",
    "latitude = tf.feature_column.numeric_column(\"latitude\")\n",
    "bucketized_latitude = tf.feature_column.bucketized_column(\n",
    "    latitude, boundaries=list(np.linspace(32., 42., 20 - 1)))\n",
    "\n",
    "# bucketize \"longitude\" column\n",
    "longitude = tf.feature_column.numeric_column(\"longitude\")\n",
    "bucketized_longitude = tf.feature_column.bucketized_column(\n",
    "    longitude, boundaries=list(np.linspace(-125., -114., 20 - 1)))\n",
    "\n",
    "# 交叉後的特徵拿去做 hash\n",
    "location = tf.feature_column.crossed_column(\n",
    "    [bucketized_latitude, bucketized_longitude], hash_bucket_size=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_house_value = tf.feature_column.numeric_column(\"median_house_value\")\n",
    "columns = [housing_median_age, median_house_value]\n",
    "feature_descriptions = tf.feature_column.make_parse_example_spec(columns)\n",
    "\n",
    "with tf.io.TFRecordWriter(\"my_data_with_features.tfrecords\") as f:\n",
    "    for x, y in zip(X_train[:, 1:2], y_train):\n",
    "        example = Example(features=Features(feature={\n",
    "            \"housing_median_age\": Feature(float_list=FloatList(value=[x])),\n",
    "            \"median_house_value\": Feature(float_list=FloatList(value=[y]))\n",
    "        }))\n",
    "        f.write(example.SerializeToString())\n",
    "\n",
    "def parse_examples(serialized_examples):\n",
    "    examples = tf.io.parse_example(serialized_examples, feature_descriptions)\n",
    "    targets = examples.pop(\"median_house_value\") # separate the targets\n",
    "    return examples, targets\n",
    "\n",
    "batch_size = 32\n",
    "dataset = tf.data.TFRecordDataset([\"my_data_with_features.tfrecords\"])\n",
    "dataset = dataset.repeat().shuffle(10000).batch(batch_size).map(parse_examples)\n",
    "\n",
    "columns_without_target = columns[:-1]\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.DenseFeatures(feature_columns=columns_without_target),\n",
    "    keras.layers.Dense(1)\n",
    "])\n",
    "model.compile(loss=\"mse\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(dataset, steps_per_epoch=len(X_train) // batch_size, epochs=5)\n",
    "\n",
    "some_columns = [ocean_proximity_embed, bucketized_income]\n",
    "dense_features = keras.layers.DenseFeatures(some_columns)\n",
    "dense_features({\n",
    "    \"ocean_proximity\": [[\"NEAR OCEAN\"], [\"INLAND\"], [\"INLAND\"]],\n",
    "    \"median_income\": [[3.], [7.2], [1.]]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 參考：TF Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF Transform 是 TFX (TensorFlow Extended) 的一部分, 將tensorflow model生產化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_transform as tft\n",
    "\n",
    "def preprocess(inputs):     # inputs is a batch of input features\n",
    "    median_age = inputs[\"housing_median_age\"]\n",
    "    ocean_proximity = inputs[\"ocean_proximity\"]\n",
    "    standardized_age = tft.scale_to_z_score(median_age - tft.mean(median_age))\n",
    "    ocean_proximity_id = tft.compute_and_apply_vocabulary(ocean_proximity)\n",
    "    return {\n",
    "        \"standardized_median_age\": standardized_age,\n",
    "        \"ocean_proximity_id\": ocean_proximity_id\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:44:08.785114: W tensorflow/tsl/platform/cloud/google_auth_provider.cc:184] All attempts to get a Google authentication bearer token failed, returning an empty token. Retrieving token from files failed with \"NOT_FOUND: Could not locate the credentials file.\". Retrieving token from GCE failed with \"FAILED_PRECONDITION: Error executing an HTTP request: libcurl code 6 meaning 'Couldn't resolve host name', error details: Could not resolve host: metadata.google.internal\".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset 11.06 MiB (download: 11.06 MiB, generated: 21.00 MiB, total: 32.06 MiB) to /Users/chenyanting/tensorflow_datasets/mnist/3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832b6df97b904b85b653805753b1a661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...:   0%|          | 0/5 [00:00<?, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to /Users/chenyanting/tensorflow_datasets/mnist/3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-03 16:44:33.685611: W tensorflow/core/kernels/data/cache_dataset_ops.cc:854] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x300 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "mnist_train = mnist_train.repeat(5).batch(32).prefetch(1)\n",
    "for item in mnist_train:\n",
    "    images = item[\"image\"]\n",
    "    labels = item[\"label\"]\n",
    "    for index in range(5):\n",
    "        plt.subplot(1, 5, index + 1)\n",
    "        image = images[index, ..., 0]\n",
    "        label = labels[index].numpy()\n",
    "        plt.imshow(image, cmap=\"binary\")\n",
    "        plt.title(label)\n",
    "        plt.axis(\"off\")\n",
    "    break # just showing part of the first batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = tfds.load(name=\"mnist\")\n",
    "mnist_train, mnist_test = datasets[\"train\"], datasets[\"test\"]\n",
    "mnist_train = mnist_train.repeat(5).batch(32)\n",
    "mnist_train = mnist_train.map(lambda items: (items[\"image\"], items[\"label\"]))\n",
    "mnist_train = mnist_train.prefetch(1)\n",
    "for images, labels in mnist_train.take(1):\n",
    "    print(images.shape)\n",
    "    print(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "datasets = tfds.load(name=\"mnist\", batch_size=32, as_supervised=True)\n",
    "mnist_train = datasets[\"train\"].repeat().prefetch(1)\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=[28, 28, 1]),\n",
    "    keras.layers.Lambda(lambda images: tf.cast(images, tf.float32)),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")])\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(mnist_train, steps_per_epoch=60000 // 32, epochs=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
